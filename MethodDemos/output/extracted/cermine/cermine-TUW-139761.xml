<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
  <front>
    <journal-meta />
    <article-meta>
      <title-group>
        <article-title>Option Pricing by means of Genetic Programming</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <string-name>Univ.-Prof. Dr. Michael Hanke</string-name>
          <xref ref-type="aff" rid="aff0">0</xref>
        </contrib>
        <contrib contrib-type="author">
          <string-name>Andreas Heigl</string-name>
          <xref ref-type="aff" rid="aff0">0</xref>
        </contrib>
        <aff id="aff0">
          <label>0</label>
          <institution>der Technischen Universitat Wien</institution>
        </aff>
      </contrib-group>
      <fpage>23</fpage>
      <lpage>64</lpage>
      <abstract>
        <p>unter Anleitung von a.o. Univ.-Prof. Dipl.-Ing. Dr.techn. Gunther Raidl</p>
      </abstract>
    </article-meta>
  </front>
  <body>
    <sec id="sec-1">
      <title>Markt 115 5611 GROSSARL</title>
    </sec>
    <sec id="sec-2">
      <title>Datum</title>
    </sec>
    <sec id="sec-3">
      <title>Unterschrift</title>
      <p>This master thesis describes how to price options by means of Genetic Programming.
The underlying model is the Generalized Autoregressive Conditional Heteroskedastic
(GARCH) asset return process. The goal of this master thesis is to nd a closed-form
solution for the price of European call options where the underlying securities follow a
GARCH process. The data are simulated over a wide range to cover a lot of existing
options in one single equation.</p>
      <p>Genetic Programming is used to generate the pricing function from the data.
Genetic Programming is a method of producing programs just by de ning a
problemdependent tness function. The resulting equation is found via a heuristic algorithm
inspired by natural evolution. Three di erent methods of bloat control are used.
Additionally Automatic De ned Functions (ADFs) and a hybrid approach are tested, too.
To ensure that a good con guration setting is used, preliminary testing of many di
erent settings has been done, suggesting that simpler con gurations are more successful
in this environment.</p>
      <p>The resulting equation can be used to calculate the price of an option in the given
range with minimal errors. This equation is well behaved and can be used in standard
spread sheet programs. It o ers a wider range of utilization or a higher accuracy,
respectively than other existing approaches.</p>
      <p>Zusammenfassung
Diese Diplomarbeit beschreibt, wie Optionen mit Hilfe Genetischer Programmierung
bewertet werden konnen. Das zugrunde liegende Modell nennt sich GARCH
(Generalized Autoregressive Conditional Heteroskedastic) Renditeprozess. Das Ziel dieser
Diplomarbeit ist eine geschlossene Formel, die als Ergebnis den Preis einer europaischen
Kaufoption liefert, dessen dahinter liegende Wertpapier einem GARCH Prozess folgt.
Die Daten werden innerhalb eines breiten Wertebereiches simuliert, um die meisten
existierenden Optionen mit einer Formel bewerten zu konnen.</p>
      <p>Die Formel wird mittels Genetischer Programmierung aus den Daten generiert.
Genetische Programmierung ist eine Methode, bei der nur durch De nition einer zum
Problem passenden Bewertungsfunktion vollstandige Programme produziert werden
konnen. Die Ergebnisgleichung wird schlie lich mittels eines der Evolution ahnlichen
Algorithmus gefunden. Drei verschiedene Methoden zum Bloat Control wurden
verwendet. Zusatzlich wurden auch Automatisch De nierte Funktionen sowie ein hybrider
Ansatz untersucht. Um sicherzustellen, dass eine gute Kon guration gewahlt wird, gibt
es Vortests vieler verschiedener Kon gurationen. Es zeigt sich, dass in diesem Umfeld
einfachere Kon gurationen erfolgreicher sind.</p>
      <p>Die Ergebnisgleichung kann schlie lich zur Errechnung der Optionspreise mit
minimalem Fehler verwendet werden. Diese Gleichung verhalt sich gut und kann auch in
Standardtabellenkalkulationen verwendet werden. Im Vergleich mit anderen
existierenden Ansatzen, bietet diese Gleichung eine weitere Verwendbarkeit beziehungsweise eine
hohere Genauigkeit.
I have to thank my family, my professors and all my friends. Special thanks to Dr.
Hanke, who has helped me to nd this interesting topic of research and to Dr. Raidl,
who has showed me how to write a good master thesis. All the brave programmers who
have made libraries I have used, are mentioned here too. Magister Katarina Kocian
has read my thesis very often to nd even the last mistake. Without these people it
would not have been possible to write this thesis.
1 Introduction
6
5.2.3 Population size, number of generations and mutation . . . . . . 34
5.2.4 Automatic de ned functions and hybrid approaches . . . . . . . 34
6 Implementation details 36
6.1 Libraries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
6.1.1 The Genetic Programming kernel . . . . . . . . . . . . . . . . . 36
6.1.2 A random number generator library . . . . . . . . . . . . . . . . 38
6.1.3 GNU Scienti c Library . . . . . . . . . . . . . . . . . . . . . . . 40
6.2 New classes and functions . . . . . . . . . . . . . . . . . . . . . . . . . 41
6.2.1 Additional functions . . . . . . . . . . . . . . . . . . . . . . . . 41
6.2.2 GPOPdata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
6.2.3 MyGPVariables . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
6.2.4 MyGene . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
6.2.5 MyGP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
6.2.6 MyPopulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
6.2.7 Executables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
6.3 Overview UML diagram . . . . . . . . . . . . . . . . . . . . . . . . . . 44</p>
      <sec id="sec-3-1">
        <title>Chapter 1</title>
      </sec>
      <sec id="sec-3-2">
        <title>Introduction</title>
        <p>Options are derivative securities. At expiration date the value of an option is exactly
determined by an underlying cash instrument. The process of nding the value of an
option before expiration date is called option pricing. The history of the theory of
option pricing began in 1900 when the French mathematician Louis Bachelier derived
an option pricing formula. His formula is based on the assumption that stock prices
follow a Brownian motion with zero drift. Since that time, numerous researchers have
contributed to the theory. In the year 1973 Fischer Black, Myron Scholes and Robert
Merton made a breakthrough in the pricing of options. They have derived a single
equation for pricing options, under the assumption of a lognormal distribution of the
underlying asset. Still there are some problems with the model's assumption.
Empirical evidence (compare with [BCK92]) has shown that the underlying securities do not
behave according to that assumption. The probability of large price changes is much
higher than it should be possible under the lognormality assumption. Another typical
feature of empirical return distributions is called heteroskedasticity, the changing of the
variance in time. In practise, many return series show volatility clustering, where bad
news lead to a signi cant increase of the volatility. After some time volatility returns
to the old value. The GARCH (Generalized Autoregressive Conditional
Heteroskedasticity) model of Tim Bollerslev is an answer to these problems. Jin-Chuan Duan has
developed an option pricing model for underlyings following GARCH processes. Still
one drawback remains. It is not possible to derive a closed-form equation for option
pricing similar to the Black-Scholes formula. Option prices can only be calculated via
Monte Carlo simulation, which is computationally expensive and time consuming.</p>
        <p>Meanwhile new approaches to solve complex problems evolved in the eld of
computer science. Many of them have been inspired by the way nature \solves problems".
Neural networks are now widely used in di erent areas. [Hol75] introduced the concept
of Genetic Algorithms, which is very successful in the eld of Operations Research.
[Koz92] enhanced the Genetic Algorithm to the so called Genetic Programming
approach, which is applicable in elds as di erent as electrical engineering and symbolic
regression (compare with [K+03]).</p>
        <p>Brokers frequently need to make decisions within seconds. Until recently it was not
possible to use the GARCH model for more than a small number of options, because
it takes too much time to perform a Monte Carlo simulation. [Han98] used a Neural
Network to overcome this problem. [DS01] provide a Markov chain approximation.
This master thesis will use Genetic Programming to derive an approximate analytic
formula for pricing options when the underlying follows a GARCH process.</p>
        <p>The thesis is organized as follows. Chapter 2 provides a brief overview of the
concepts of option pricing. Chapter 3 introduces Genetic Programming. Chapter 4
gives an overview of existing approaches. They are all related to this work and are used
as a benchmark for the results. Our new approach is presented in chapter 5. It shows
also the strategic modus operandi of this work. Chapter 6 discusses implementation
issues. This chapter also gives information about the libraries used, which are freely
available on the internet. Chapter 7 gives a detailed experimental analysis of the results
and a comparison to existing approaches. It includes statistical tests to nd out the
best con gurations. Chapter 8 concludes this master thesis and gives some suggestions
for further research.</p>
      </sec>
      <sec id="sec-3-3">
        <title>Chapter 2 Option pricing</title>
        <p>This chapter gives a brief overview of option pricing and shows approaches which are
used in later chapters. A comprehensive introduction to option pricing can be found
in [Hul02]. Some of the more complex mathematical aspects can be found in [Nef00].
2.1
2.1.1</p>
        <sec id="sec-3-3-1">
          <title>Basic approaches in option pricing</title>
          <p>Some de nitions and basic models
According to [Nef00], p. 2 \a nancial contract is called a derivative security, or a
contingent claim, if its value at expiration date T is determined exactly by the market
price of the underlying cash instrument at time T. Hence, at the time of expiration of
the derivative contract, denoted by T, the price F(T) of a derivative asset is completely
determined by S(T), the value of the underlying asset. After that date, the security
ceases to exist."</p>
          <p>The underlying asset can be
currencies,
interest rates,
indexes</p>
        </sec>
      </sec>
    </sec>
    <sec id="sec-4">
      <title>Futures and forwards</title>
      <p>Options
Swaps
commodities like crude oil, gold and many more.</p>
      <p>It is possible to group derivative securities under three general headings:</p>
      <p>A future and a forward contract is an obligation to buy (or sell) an underlying asset
at a speci ed price on a known date. If the speci ed price is not equal to the market
price of the underlying at expiry the holder of the contract makes a loss or a pro t.</p>
      <p>In contrast to that, an option is the right, but not the obligation to buy (or sell)
the underlying asset at a speci ed price on a speci ed date. The speci ed price in
the contract is known as the exercise price or strike price. The speci ed date in the
contract is known as the expiration date or maturity. If it is a right to buy it is a call
option, if it is a right to sell it is a put option (compare with [Hul02] p. 1 - 15).</p>
      <p>Options may be classi ed by their exercise mode:
American options can be exercised at any time up to the expiration date.
European options can only be exercised on the expiration date itself.</p>
      <p>If X is the strike price and ST is the nal price of the underlying asset, the payo
at the expiration time of a European call option is
max(ST</p>
      <p>X; 0):
max(X</p>
      <p>ST ; 0):
This re ects the fact that the option will be exercised if ST &gt; X and will not be
exercised if ST &lt; X. Similarly the payo at expiration time of a European put option
is
(2.1)
(2.2)
Before expiration, the price of a stock option is a ected by six factors ([Hul02]):
Current stock price.</p>
      <p>Strike price.</p>
      <p>Risk-free interest rate
Volatility of the stock price, which is the annualized standard deviation.
Time to expiration.</p>
      <p>Dividends expected during the life of the option.</p>
      <p>If the current stock price is high then it is more likely that the stock price at
expiration time will be high too. According to equation 2.1 the value of a call option
will be higher when the stock price is higher at expiration time. The strike price is not
subject to change until the expiration date and in uences the value of the option in a
direct manner.</p>
      <p>The risk-free interest rate a ects the price of an option in a less clear-cut way. As
interest rates in the economy increase, the expected growth rate of the stock price
tends to increase. However, the present value of any future cash ow received by the
holder of the option decreases.</p>
      <p>As volatility increases, the chance that the stock will do very well or very poorly
increases. For the owner of the underlying, these two outcomes tend to o set each other.
However the owner of a call bene ts from price increases but has limited downside risk
in the event of price decreases because he has no obligation to exercise the option.
Therefore as volatility increases the value of an option also increases.</p>
      <p>The time to expiration in uences the value of a call option in two ways. More time
until expiration means a higher change of large changes in the underlying price, which
increases the price of options. At the same time more interest has to be paid. This
decreases the value of an option.</p>
      <p>According to [Hul02] p. 170, dividends have the e ect of reducing the stock price
on the ex-dividend date. This is bad news for the value of call options and good news
for the value of put options. The value of a call option is therefore negatively related
to the size of any anticipated dividends, and the value of a put option is positively
related to the size of any anticipated dividends.</p>
      <p>The moneyness ratio is de ned as St=X. A call option is called out-of-the-money if
the moneyness ratio is less than 1. If it is worth more than 1, it is called in-the-money.
In case it is close to 1 it is called at-the-money.
2.1.2</p>
      <p>The Black-Scholes formula
As long as it is possible to determine which process the underlying will follow in the
future it is possible to calculate the price of an option before the expiration date too.
Because there are countless factors which can in uence the price of a stock and these
factors are usually not known in advance the process cannot be deterministic, but is
stochastic.</p>
      <p>Stochastic processes can be classi ed as discrete-time or continuous-time. A
discrete-time stochastic process is one where the value of the variable can change only
at certain xed points in time, whereas a continuous-time stochastic process is one
where change can take place at any time (compare with [Hul02] p. 216).</p>
      <p>A Wiener process or Brownian motion is a continuous-time stochastic process. It
is a particular type of Markov stochastic process with a mean change of zero and a
variance rate of 1.0 per year. A good overview of the properties of a Wiener process
may be found in [Nef00] p. 173 - 202.</p>
      <p>We are assume that the underlying follows a generalized Wiener process
dS =</p>
      <p>Sdt + Sdz
(2.3)
where S is the price of the underlying, dt is the time between two measure points,
is the expected return of the underlying, is the volatility of the process and z is a
standard Wiener process.</p>
      <p>This equation implies that stock prices have the lognormal property. This means
that the percentage changes (dS=S) of stock prices are normally distributed.</p>
      <p>[BS73] found a solution to a stochastic di erential equation derived from this process
by constructing a locally riskless hedge-portfolio. This leads to the following formula</p>
      <sec id="sec-4-1">
        <title>Discrete-time</title>
        <p>GARCH model
stochastic
processes
and
the
for pricing call options:
where
and
2.2
pT
The function N (x) is the cumulative standard normal probability distribution
function. Furthermore r is the riskless interest rate and T is the time left to maturity. A
derivation of this formula can be found in [Nef00].
2.2.1</p>
        <p>Discrete-time stochastic processes
Another approach to model the price process of the underlying are discrete-time
stochastic processes. In contrast to the generalized Wiener process, only discrete time
steps are used. The discretized version of the generalized Wiener process leads to the
following equation:
where St is the price of the underlying at time t, is its expected return, its volatility
and "t is a normally distributed random variable with mean 0 and variance 2. The
left-hand side of the equation is de ned as the yield (y) of the underlying. With the
yield it is possible to calculate St from St 1 via the following formula:</p>
        <p>St
St 1
=
2
2</p>
        <p>+ "t
St = St 1ey
(2.4)
(2.5)
(2.6)
(2.7)
(2.8)</p>
        <p>As can be seen from equation 2.7 the Black-Scholes model assumes that the
probability distribution of the underlying asset at any given future time is lognormal, which
is a less than perfect assumption because the probability of high losses and pro ts is
much higher in reality. Therefore the true probability distribution seems to have a
higher kurtosis than the normal distribution. Another wrong assumption of the
BlackScholes model is that the volatility of the underlying is constant in time (compare
[Hul02] p. 331 - 345).
2.2.2</p>
        <p>The GARCH model
The Generalized Autoregressive Conditional Heteroskedasticity (GARCH) model was
rst introduced by [Bol86]. It is a more exible variant of the ARCH model proposed
parameter</p>
        <p>St=X
r
2</p>
        <p>t
by [Eng82]. A good overview of the di erent types and applications of the GARCH
model can be found in [BCK92].</p>
        <p>The GARCH model is a discrete-time stochastic process. Every GARCH process
consists of two equations. One de nes the mean, the other the conditional variance.
The yield of a GARCH(1,1) process is de ned as
(2.9)
(2.10)
y =</p>
        <p>St
with
where r is the riskless interest rate, St is the price of the underlying at time t, is the
risk premium, ht is the conditional variance, a0, a1, b1 are GARCH parameters and t
is a normally distributed random variable with mean 0 and variance ht ( t N (0; ht)).</p>
        <p>The di erence between a GARCH process and the discretized Geometric Brownian
motion (used in the Black-Scholes model) is that the variance may now change over
time. The variance (ht) depends on the GARCH parameters (a0, a1, a2), the variance
from one period before and random disturbances ( t). Although t is normally
distributed, the unconditional variance of the whole process is not normally distributed.
Therefore, depending on the values of the GARCH parameters, the distribution is not
the same as in the Black-Scholes framework (compare with [Han98]).</p>
        <p>Usually a GARCH process is estimated by the maximum-likelihood method, where
all parameters (a0, a1 and b1) are estimated at the same time. To produce sample
time-series Monte Carlo simulation might be used. Until yet it was not possible to nd
a solution for the di erential equations of the GARCH process in general.
2.2.3</p>
        <p>Monte Carlo simulation of a GARCH process
The data will be simulated according to [Dua95] and [GS96]. In [Dua95] the concept
of locally risk-neutral valuation relationship (LRNVR) was introduced. The LRNVR
leads to a transformation of the formula of the yield and the conditional variance,
which holds under realistic assumptions about the behavior of investors.</p>
        <p>The given input data are shown in table 2.1 and are usually estimated from historical
data. The condition a1 + b1 &lt; 1 must always be satis ed, otherwise the unconditional
variance is not de ned. The GARCH parameter a0 is given by the following formula:
The next conditional variance is given by
where t2 = ht in the rst case. Next time the ith instance (this means the ith path of
simulation) of t+1;i is constructed with standard normal random numbers zt+1;i:</p>
      </sec>
    </sec>
    <sec id="sec-5">
      <title>We get the yield with</title>
      <p>The yield, error term and conditional standard deviation at the next time points u =
t + 2; :::; T are calculated equally:
(2.11)
(2.12)
(2.13)
(2.14)
(2.15)
(2.16)
(2.17)
(2.18)
(2.19)
with
and
At the end we get the new moneyness ratio of the share:
yu;i = r
hu;i + u;i</p>
      <p>2
u;i = qhu;izu;i
hu;i = a0 + a1( u 1;i
q</p>
      <p>hu 1;i)2 + b1hu 1;i
ST;i = St ePTu=t+1 yu;i</p>
      <p>X X
And nally the price of an European call option relative to the strike price K at time
t:</p>
      <p>Ct;i = e r(T t) max( ST;i 1; 0) (2.20)</p>
      <p>X X</p>
      <p>To decrease the variance of the di erent simulation paths variance reduction
methods are used. This reduces the time to do the simulation. [BBG97] describes the
theoretical fundamentals of this approach. Three methods are described.</p>
      <p>The method of antithetic variates is described in [BBG97]. For each set of random
numbers (zui) another set with negative values of these random numbers ( zui) is
calculated. An option price is calculated by using the original random numbers (zui),
another by using the negative value of the original random numbers. The variance
reduced price is the average of these two prices.</p>
      <p>The second is the Empirical Martingale Simulation (EMS) introduced by [DS95].
It is a simple enhancement of the Monte Carlo simulation that ensures that the price
estimated satis es rational option pricing bounds. The new simulation procedure
generates the EMS asset prices at a sequence of time points, t1, t2, ..., tm using the following
dynamics:</p>
      <p>Si (tj; n) = S0</p>
      <p>Zi(tj; n)
Z0(tj; n)
where</p>
      <p>Zi(tj; n) = Si (tj 1; n)
Z0(tj; n) =
1
n</p>
      <p>n
e rtj X Zi(tj; n)
i=1</p>
      <p>Si(tj)
Si(tj 1)
Note that Si(t) is the ith simulated asset path at time t prior to the EMS adjustment.</p>
      <p>The last one is called the control variate method which is described in [BBG97].
With the same random numbers used in the calculation of GARCH prices (P gsim)
Black-Scholes prices are simulated by using equation 2.8 which leads to a simulated
Black-Scholes price (P bssim). But the Black-Scholes price (P bsana) can also be calculated
analytically by the Black-Scholes formula given in 2.4. The new GARCH(1,1) price
(P gcv) after the control variate correction is</p>
      <p>P gcv = P gsim
(P bssim</p>
      <p>P bsana)
The
should be chosen to minimize the variance and is therefore:
=</p>
      <p>Cov[P gsim; P bssim]</p>
      <p>V ar[P bssim]
(2.21)
(2.22)
(2.23)
(2.24)
(2.25)</p>
      <sec id="sec-5-1">
        <title>Chapter 3</title>
      </sec>
      <sec id="sec-5-2">
        <title>Overview of Genetic Programming</title>
        <p>Genetic Programming has been introduced in [Koz92]. It is based on genetic
algorithms which were originally described in [Hol75]. These two basic approaches will be
introduced in the following sections.
3.1</p>
        <sec id="sec-5-2-1">
          <title>Genetic algorithms</title>
          <p>This section gives a brief overview of genetic algorithms. More information can be found
in [BFM97] or in [Mic92]. In biology the evolutionary process results in a selection of
the ttest individual in a given environment. The environment might be a speci c area,
a continent or the whole world. In [Hol75] a general framework for adaptive systems
is given. The book shows how these adaptive systems (like the evolutionary process)
might be applied to arti cial systems. Any problem in adaptation can generally be
formulated in genetic terms. Once formulated in those terms, such a problem can
often be solved by what we now call the \Genetic algorithm" (compare with [Koz92],
p. 17-18).</p>
          <p>[Mic92], p. 14 states:
\The idea behind genetic algorithms is to do what nature does. Let us take
rabbits as an example: at any given time there is a population of rabbits.
Some of them are faster and smarter than other rabbits. These faster,
smarter rabbits are less likely to be eaten by foxes, and therefore more of
them survive to do what rabbits do best: make more rabbits. Of course,
some of the slower, dumber rabbits will survive just because they are lucky.
This surviving population of rabbits starts breeding. The breeding results
in a good mixture of rabbit genetic material: some slow rabbits breed with
fast rabbits, some fast with fast, some smart rabbits with dumb rabbits and
so on. And on the top of that, nature throws in a `wild hare' every once in
while by mutating some of the rabbit genetic material. The resulting baby
rabbits will (on average) be faster and smarter than those in the original
population because more faster, smarter parents survived the foxes."
3.1.1</p>
          <p>Basic terminology
A genetic algorithm works on individuals (or genotypes, structures), which might be
a living organism in nature or a solution to a known problem in an arti cial system
(=environment ). Each individual is completely described by its constant-size genome.
This genome or chromosome may be encoded in bits and bytes, alphanumerical letters
or nucleotide bases, like it is done in nature. Chromosomes are also called strings. In
nature every species carries a certain number of chromosomes (humans for example,
have 46 of them). However in arti cial problems usually one chromosome is su cient.
Chromosomes are made of units - genes (also called features, characters) - arranged
in linear succession. Every gene controls the inheritance of one or several characters
(compare with [Mic92]).</p>
          <p>Every individual has an associated tness value. This tness value describes the
capability of an individual to survive in the environment. Operations designed to mimic
the Darwinian principle of reproduction and survival of the ttest are used on a set of
individuals (=population). A population therefore consists of many individuals which
are in general di erent, but it can also contain identical individuals. An algorithm
describes which individuals are going to survive where the individuals with better
tness will have a competitive advantage.</p>
          <p>According to [Mic92] p. 17-18 a genetic algorithm for a particular problem must
have the following ve components:
a genetic representation for potential solutions to the problem,
a way to create an initial population of potential solutions,
an evaluation function that plays the role of the environment, rating solutions in
terms of their tness,
genetic operators that alter the composition of children during reproduction,
values for various parameters that the genetic algorithm uses (population size,
probabilities of applying genetic operators, etc.).</p>
          <p>Genetic operations which determine a genetic algorithm are
reproduction where one individual can reproduce itself (in real life this means that
it is able to live longer than the others).
crossover or sexual reproduction where two individuals (parents) produce one or more
individuals.
mutation where the genome of an individual (and therefore the individual itself too)
are changed in a random way.</p>
          <p>Create initial
random population</p>
          <p>Termination
criterion satisfied?</p>
          <p>Yes</p>
          <p>No
Evaluate fitness of
each individual in
population
i:=0
i=M?
No</p>
          <p>Designate
result</p>
          <p>End
Gen:=Gen+1</p>
          <p>Yes</p>
          <p>Pr</p>
          <p>Select one
individual based
on fitness</p>
          <p>Perform
redproduction
Copy into new
population</p>
          <p>Select genetic operation
probabilistically</p>
          <p>Pc</p>
          <p>Select two
individuals based
on fitness
i:=i+1
Perform
Crossover</p>
          <p>Insert two
offspring into new
population
i:=i+1</p>
          <p>Pm</p>
          <p>Select one
individual based</p>
          <p>on fitness
Perform mutation
Insert mutant into
new population
3.1.2</p>
          <p>Flowchart of a simple genetic algorithm
In gure 3.1 the basic steps of a genetic algorithm are shown. First the generation
(=population) counter is set to zero. Then an initial population is generated randomly
and the tness of each individual in the population is examined. If the termination
criterion is already satis ed, the genetic algorithm will stop and the result may be used.
The termination criterion might be a limit on the number of generations or a speci c
quality criterion of the individuals. The result is usually the best individual found in
the whole algorithm.</p>
          <p>To produce a new generation the variable i counts the number of new individuals,
which will be set to zero initially. The number of individuals in each population equals
M . The next steps are repeated until M new individuals have been created.</p>
          <p>The three di erent genetic operations are chosen randomly. With probability Pr
an individual is simply selected, reproduced and copied to the new population. With
probability Pm an individual will be mutated and with probability Pc crossover will
occur. In this case two individuals are selected, some kind of crossover is performed
and the two o spring are copied into the new population.</p>
          <p>This is repeated until the new generation is completed. The generation counter is
now increased. Then the tness of each individual is evaluated to nd out whether the
termination criterion is satis ed.
3.1.3</p>
          <p>Additional settings
There are numerous minor variations of the basic genetic algorithm shown in gure
3.1. Some approaches put the mutation operation after crossover and reproduction
with some (low) probability. It is not shown how the crossover operation is done
exactly. This is often domain dependent, which means that it depends on the speci c
problem the genetic algorithm is supposed to solve.</p>
          <p>Another variation is called the steady state framework which is rst used in [Rey92]
and was originally proposed in [Hol75]. In this case the new population is not produced
at once and then replaces the old one, but there exists just one population. The
parents are chosen from this population and the generated o springs are immediately
incorporated into the population by replacing one or two existing individuals. The
individuals to be replaced can be the worst or randomly chosen ones. An iteration
(generations do not exist any more) is considered as completed, once the number of
children created by this method is equal to the size of the population. This procedure
saves memory and increases the convergence. The disadvantage is that it increases the
danger of premature convergence which leads to worse results.</p>
          <p>Two selection strategies are important to mention (compare [Fra94]). Possible
solutions or chromosomes are assigned a tness f by the tness function. In tness
proportionate selection, the probability P selection that a speci c individual y will be
selected is</p>
          <p>P selection =
y
PxN=1 fx
(3.1)
where N is the number of individuals in the population. While candidate solutions with
a lower tness will be less likely to be selected, there is still a chance that they may be.
Contrast this with a less sophisticated selection algorithm, such as truncation selection,
which will choose a xed percentage of the best candidates. With tness proportionate
selection there is a chance some weaker solutions may survive the selection process; this
is an advantage, as though a solution may be weak, it may include some components
which could prove useful following the recombination process.</p>
          <p>Tournament selection chooses a speci c number of individuals from the population
(for example 10). These individuals are selected randomly with each individual having
the same probability to be chosen. Then the best one or best two of these individuals
will be selected for the genetic operation. This method is easier to implement and
more robust than tness proportional selection. The disadvantage is that the tness
measure is no longer an absolute value which determines the probability to be chosen.
The tness measure just provides a relative measure for the selection process.</p>
          <p>With demetic grouping the selection process may also be altered. In this case the
whole population is subdivided into a number of groups. These groups undergo their
own genetic algorithm and interact only rarely. This allows the demes to evolve along
separate paths with solutions di ering more from each other, which might lead to better
individuals at later generations.
3.2</p>
        </sec>
        <sec id="sec-5-2-2">
          <title>Genetic Programming</title>
          <p>Genetic Programming was introduced by [Koz92]. A good introduction can be found in
[BNKF98]. It is an extension of the genetic algorithms where the chromosomes are of
variable size. The chromosomes now describe hierarchical computer programs encoded
in tree-like structures. This leads to additional complexity and some further issues
described in the following subsections.</p>
          <p>According to [KBAK99], p. 33 the ve major preparatory steps for Genetic
Programming entail determining
1. the set of terminals (e.g., the actual variables of the problem, zero-argument
functions, and random constants, if any) for each branch of the to-be-evolved
computer program,
2. the set of primitive functions for each to-be-evolved branch,
3. the tness measure (or other arrangements for explicitly measuring tness),
4. the parameters for controlling the run, and
5. the termination criterion and the method of result designation for the run.
Methods
printOn
printMathStyle
printTeXStyle
evaluate</p>
        </sec>
      </sec>
    </sec>
    <sec id="sec-6">
      <title>Description</title>
      <p>Output function
Output function to ASCII style</p>
      <p>Output function to TeX style</p>
      <p>Evaluates the gene
depending on a global variable. The printTeXStyle method prints a Gene according to
the TeX style and the printMathStyle according to a normal math style with brackets.</p>
      <p>One of the core functions in Genetic Programming is the evaluate method. It
calculates the result of a single gene. It has to provide values for the whole function
set de ned in the genetic program. The value of variables and constants used in the
genetic program has to be returned, too. If ADFs (compare with chapter 3.2.4) exist,
it has to provide the arguments of the ADFs.
6.2.5</p>
      <p>MyGP
The class MyGP is derived from the GP class of the Genetic Programming kernel. Table
6.6 shows all the methods which have to be rewritten. The printOn method outputs all
the necessary information for TeX style output les. The evaluation method calculates
the tness of a genetic program. It calculates the root of the average of the squared
errors of all data points (compare with chapter 5.2.2).
6.2.6</p>
      <p>MyPopulation
The class MyPopulation is derived from the GPPopulation class of the Genetic
Programming kernel. Table 6.7 shows all the methods which have to be rewritten. The
tournamentSelection method has to be rewritten to provide death by size as bloat
control method.
6.2.7</p>
      <p>Executables
According to chapter 5, four di erent strategies to solve the problem are used. This
leads to four di erent executables ( les which are executed by the operating system)</p>
      <p>Methods Description
tournamentSelection Rewrites the selection strategy
for Genetic Programming. They only di er in the type of function which are
predetermined for evaluation and in the number and type of ADFs used. Table 6.8 shows
the di erent executables which are produced and what they are supposed to do. They
also correspond to the four di erent approaches from table 5.4.</p>
      <p>Proddata is the executable le which simulates the GARCH process to get the
sample data points (compare with chapter 6.2.2).
6.3</p>
      <sec id="sec-6-1">
        <title>Overview UML diagram</title>
        <p>G ie ib
c L
S
*
..
1
*
..
1 1
1
1
1
e
n
e
G
y
M
P
G
t
e
S
e
d
o
N
P
G
l
a
m
r
o
N
1
*
..
1
*
.
. 1
1
P
G
y
M
n
o
i
t
a
l
u
p
o
P
P
1
1
t
e
S
e
d
o
A
P
G
1
*
..
1
N
1 f
d
*
..
1
1
1
P
y
G
y
1
1 P
1
1
1
1</p>
        <sec id="sec-6-1-1">
          <title>Chapter 7</title>
        </sec>
        <sec id="sec-6-1-2">
          <title>Results and statistics</title>
          <p>This chapter shows the results of the best genetic programs found. In the early stages
I have tried to gure out which is the most promising con guration. Therefore the
chapter starts with a statistical test of di erent con gurations. Afterwards the best
genetic program found is introduced and some properties of this equation are shown.
At the end, my result is compared with the three existing approaches described in
chapter 4.</p>
          <p>Statistics of
con guration
the
identi cation
of the
best
7.1.1</p>
          <p>Setting of the test environment
Each of the two con gurations from 5.2.2 (with and without mutation) is used with
the three bloat control methods described in chapter 5.2.2. Additionally, all 6 resulting
approaches are tried with a Student t distribution and with a standard normal
distribution. This leads to 12 di erent test cases where each test is repeated 25 times to get
statistically relevant results. Table 7.1 shows all di erent test cases.</p>
          <p>Due to the huge number of test cases (12 25 = 300), the control parameters
(compare with chapter 3.2.6) have been chosen as run-time decreasing and as little
memory consuming as possible:
1. The con guration without mutation is used with a population size of 30000 and
for 50 generations.
2. The con guration with mutation is used with a population size of 3000 and for
500 generations.
3. In the depth limiting bloat control method, the maximum depth parameter is set
to 7.
No. con guration
1 without mutation
2 without mutation
3 without mutation
4 without mutation
5 without mutation
6 without mutation
7 with mutation
8 with mutation
9 with mutation
10 with mutation
11 with mutation
12 with mutation
bloat control cdf used
depth limiting normal
depth limiting student-t
parsimony pressure normal
parsimony pressure student-t
death by size normal
death by size student-t
depth limiting normal
depth limiting student-t
parsimony pressure normal
parsimony pressure student-t
death by size normal
death by size student-t
4. In the death by size and the parsimony pressure bloat control method, the
maximum depth is set to 20.
5. The penalty parameter in the parsimony pressure bloat control method is set to
only 20000.
7.1.2</p>
          <p>Test results
where X N ( x; 2) and Y N ( y; 2) are the two stochastic variables, Sy2 and Sx2
are the variances of the sample, and Y n and Y m are the averages of the sample.</p>
          <p>The hypothesis H0 : x = y has to be abolished, when the following equation
holds:
with the probability</p>
          <p>Z =</p>
          <p>xm yn
q( m1 + n1 ) (m 1)s2m+(n 1)s2n</p>
          <p>m+n 2
of rejecting a correct null hypothesis.</p>
          <p>tm+n 2;1 2
(7.2)</p>
          <p>Mean
0.01532
0.01545
0.01875
0.01825
0.04356
0.04361
0.01853
0.02057
0.02512
0.02978
0.06559
0.06884</p>
          <p>The result of the t-test of each tuple of con guration is shown in table 7.3. This
table shows the probability in percent of - the probability of rejecting a correct null
hypothesis. If is higher than 5%, I have assumed that the two con gurations are
of the same quality. Additionally this table shows which con guration is better with
respect to the mean value according to table 7.2. A grey entry signi es that the row
con guration is better (on average) than the column con guration. If the entry is
black, it is vice versa.</p>
          <p>The con guration with mutation leads in all cases to a signi cantly worse result
than the con guration without mutation. Also the execution time is most of the time
longer with mutation. Therefore, I have decided to prefer the con guration without
mutation for all further experiments.</p>
          <p>The death by size bloat control method doesn't work well in my analysis. It kills all
the long genetic programs immediately and at the same time the entire gene pool. At
the end a couple of very small genetic programs survive with a very bad performance.
The execution time is extremely short. The depth limiting bloat control method
performs in most cases equally well as the parsimony pressure method, but it takes on
average twice as much time. Therefore the Penalty factor has been set to low to allow
a suitable judgement. I will use both methods in my further experiments. Death by
size will be discarded, due to its poor performance.</p>
          <p>The usage of the Student-t or the normal cumulative distribution function as
function in the Genetic Programming algorithm doesn't lead to signi cantly di erent
results in all cases. This might be because the normal distribution is a special case of the
Student-t distribution. The additional properties of the Student-t distribution do not
lead to better results. Usually the execution time is slightly higher with the Student-t
distribution.
7.1.3</p>
          <p>Utilization of the ADFs and the hybrid approaches
In order to identify which approach (compare with chapter 5.2.4) is the best one, all
approaches have been tested with the best con gurations. The standard with ADF
approach is even tried with all con gurations. In the case of signi cantly di erent
results, this would show that there are some interdependencies.</p>
          <p>Table 7.4 shows the performance of ten runs for each con guration with the ADF
approach. It is worse than the average of the standard con guration in all cases.
I conclude therefore that the approach with ADF does not lead to better results.
This might be because it is not possible to divide the problem into easily solvable
subproblems. Another conclusion is that the di erent con gurations lead to comparable
results as before. I assume that this is a general pattern.</p>
          <p>The hybrid approach was not successful. In both cases with and without ADFs it
has not worked in the way that I expected. In all cases results are worse than with the
simpler methods. Another drawback was the usage of the Paretian stable distribution
function. It is complicated to calculate (with numerical integrals), which takes a lot
of time (20 times longer than with a normal distribution function), but has not led to
better results (not even results of equal quality).
7.2</p>
        </sec>
      </sec>
      <sec id="sec-6-2">
        <title>Comparison of the best equation found with the original process</title>
        <p>7.2.1</p>
        <p>Setting of the Genetic Algorithm
To get the best possible results, the most promising con gurations have been tested
with all approaches. Additionally, the control parameters are set to the maximum
values, where preliminary tests have indicated that they will lead to best results.
1. This leads to a maximum population size of 50000,
2. the number of generations is still set to 50,
3. the maximum depth in the depth limiting bloat control method is set to 10
4. and the penalty factor in the parsimony pressure bloat control method is set to
200000.</p>
        <p>This con guration does not over ow my memory with 512 MByte RAM and only
takes reasonable time (around 10 hours) on the average.
7.2.2</p>
        <p>The result
The best equation has been found after months of exhaustive testing with the most
promising con gurations. It has been discovered with the depth limiting con guration
without mutation and the simple approach without ADFs. The best found equation is
(with some simpli cations):
f1 = max((max(NORMAL(min(ln( XS ); dt r)); XS ) (max(min(a1 b1; a1dt 2) +
2 S ) + max(ln( XS ); min(min(b1; dt</p>
        <p>X
min(ln(XS ); min(ln(XS ); min(min((dt + b1 + e) max(XS ; 1)</p>
        <p>(XS ))))); max((max(max(ln( XS ); min(dt + max(XS ; 1); dt r)); XS )
(max(ar1+ht (dt 2 + dt 2) + ar1+ht a1b1; max(dt 2; ar1+ht (dt 2 + dt 2)))))
(min(((ln(XS )) XS + dt) 2; (dt + ln(XS )) XS
(dt 2 + dt 2); dt r))); XS
((dt 2 + dt</p>
        <p>r+ht
2 XS ) + max((ln(XS )) 2; min(a1
(r+ht )
2)dt 2)
(max(min(ln(XS );Lambda+XS )+ar1+ht (dt 2+dt 2); min(dt 2; ln(XS ))))))</p>
        <p>b1+e</p>
        <p>The complete equation in Microsoft EXCEL style:
max((max(STANDNORMVERT(min(min(ln(S/X);ln(S/X));dt*r));S/X)(max(min(a1*b1;a1^(dt*Sigma2))+a1^(r+ht/Sigma)*(dt*Sigma2+dt*Sigma2);
max(min(ln(S/X);ln(S/X))+min(dt*Sigma2;pi+r);dt*Sigma2*
(dt*Sigma2+dt*Sigma2)))))*(min(dt*Sigma2;((dt+dt*Sigma2)*
(S/X-0)*Sigma2)/(1/S/X))+max(ln(S/X);min(min(b1;dt*Sigma2);dt*r)))+
min(ln(S/X);min(ln(S/X);min(min((dt+b1+e)*max(S/X;1)*Sigma2;dt*r);
STANDNORMVERT(1-(max(S/X-0;S/X))))));max((max(max(ln(S/X);
min(dt+max(S/X;1);dt*r));S/X)-(max(a1^(r+ht/Sigma)*
(dt*Sigma2+dt*Sigma2)+a1^(r+ht/Sigma)*a1*b1;max(dt*Sigma2;
a1^(r+ht/Sigma)*(dt*Sigma2+dt*Sigma2)))))*(min(((ln(S/X))/(1/S/X)+dt)*
Sigma2;((dt+ln(S/X))*(S/X-0)*Sigma2)/(1/S/X))+max((ln(S/X))/
(r+ht/Sigma)*Sigma2;min(a1^(r+ht/Sigma)*(dt*Sigma2+dt*Sigma2);dt*r)));
max(S/X-0;S/X)-((dt*Sigma2+dt*Sigma2)^(dt*Sigma2))-(max((min(ln(S/X);
Lambda+S/X)+a1^(r+ht/Sigma)*(dt*Sigma2+dt*Sigma2))/(b1+e);
min(dt*Sigma2;ln(S/X))))))
Number of data points</p>
        <p>1000
10000</p>
      </sec>
    </sec>
    <sec id="sec-7">
      <title>RMSE of best equation 0.010656375 0.010115501</title>
    </sec>
    <sec id="sec-8">
      <title>RMSE of Black- Improvement Scholes 0.014230704 25.12 % 0.013133606 22.98 %</title>
      <p>To get some idea about the original GARCH process, I have simulated the option prices
100 times with 9 di erent settings. The values for S=X and dt varies according to table
7.6 and the values for r, 2, ht= , a1, b1 and have been set to 0:05, 0:5, 1:0, 0:8, 0:15
and 0:001, respectively.</p>
      <p>In table 7.7, the standard deviation of the original process, the RMSE of the best
equation and the RMSE of the Black-Scholes formula are shown with respect to the
simulated data described above. The average standard deviation is 0:00085 and the
RMSE is an order of magnitude higher. This seems to be realistic, because it is not
possible to construct a formula which reaches a value that is lower than the standard
deviation of a constant data set. In this case, the RMSE of the Black-Scholes formula
is three times inferior on average. Depending on the value of S=X and dt, the RMSE
varies between 0.00290 and 0.02019. This indicates that better results are still possible.</p>
      <p>Figure 7.1 shows that the RMSE of the best equation found behaves regularly in
comparison to the RMSE of the Black-Scholes formula (compare with gure 7.2). The
best found equation has therefore no signi cant bad properties at a speci c point.</p>
      <p>A di erent error measure which may be of economical interest is the Mean Absolute
Percentage Error (MAPE) which is de ned as follows:
N n=1 j y(n) j</p>
      <p>e(n)
M AP E =
(7.3)</p>
      <p>Name
data-095-30
data-095-60
data-095-90
data-100-30
data-100-60
data-100-90
data-105-30
data-105-60
data-105-90</p>
      <p>Average
0.02000
0.01000
0.00000
0.95</p>
      <p>90
1.00
Moneyness ratio</p>
      <p>1.05</p>
      <p>30
60 Maturity
0.04000
0.02000
0.01000
0.00000
30
60 Maturity
0.95</p>
      <p>90
1.00
Moneyness ratio</p>
      <p>1.05
where N is the number of data points, e is the error term and y is the Genetic
Programming result.</p>
      <p>Table 7.8 shows the di erent option prices the three methods get with the 9 constant
data sets. In all cases the newly found equation leads to better results than the
BlackScholes formula. Still the MAPE is between 2:43% (which seems to be acceptable) and
27:66% (which seems to be too high).</p>
      <p>In gure 7.3 one can also observe the much higher relative di erences at an
expiration time of 30 days than at 90 days in all cases. The RMSE (compare with gure 7.1 is
much better behaved than the MAPE, which is logical, because the driving force (the
tness function) is in my case the RMSE. To get better relative di erences I should
have used the MAPE as tness function or maybe a combination of both. But this
would increase the calculation complexity. With the Black-Scholes formula such a
relation is not observable. Figure 7.4 shows that the Black-Scholes formula seems to have
a signi cantly higher MAPE around the at the money point (where S=X equals 1:0).
7.3</p>
      <p>Comparison
approaches
of
the
results
with
other
This section compares the equation generated via Genetic Programming with the three
existing approaches described in chapter 4.</p>
      <p>Name
data-095-30
data-095-60
data-095-90
data-100-30
data-100-60
data-100-90
data-105-30
data-105-60
data-105-90</p>
      <p>Average
30.00%
25.00%
20.00%
10.00%
5.00%
0.00%
0.95</p>
      <p>1.00
Moneyness ratio</p>
      <p>1.05
90</p>
      <p>30
60 Maturity
MAPE</p>
      <p>1.00
Moneyness ratio
60 Maturity
7.3.1</p>
      <p>Comparison of the result with [Han98]
In [Han98] the best found neural network has a RM SE of 5:63 10 4 which is much
better than the 101:16 10 4 I get in my result equation. The analysis of the simulated
price paths (compare with table 7.7) shows that even the standard deviation is higher
with a value of 8:5 10 4. Therefore I conclude that a result with this accuracy is not
possible in my setting.</p>
      <p>Another di erence is that I have simulated the data in a much wider range. In
[Han98] the expiration time has been simulated between 1 and 30 days and the
annualized unconditional variance between 0:01 and 0:16. In comparison, I have used the
range [1; 90] for the maturity and [0:01; 1:00] for the unconditional annualized variance,
respectively. These data simulate a higher number of options and o er a broader
application, but lead at the same time to a higher variance of the original Monte Carlo
simulation.
7.3.2</p>
      <p>Comparison of the result with [DS01]
[DS01] price options where the underlying follows a GARCH process via a Markov
chain approximation. They use xed values for all variables except for the expiration
time and the moneyness ratio. This leads to a lower variance of the original process
than in my analysis. What is more complex in [DS01] is the usage of the NGARCH(1,1)
model, where the leverage e ect is considered too. Still the results can be compared.</p>
      <p>At di erent maturities they get an error between 6 10 3 and 12 10 3 which is as
good than my average value of 10:116 3. It seems that the approach of [DS01] and my
new approach are equally suitable to price options in a GARCH framework. I think
that my result of using only a single formula is easier than solving a 3 dimensional
Markov chain. Therefore it is more likely to be used in practise.
7.3.3</p>
      <p>Comparison of the result with [Keb99]
The quality of the results is not comparable because Keber uses a di erent type of
option with a di erent model for the underlying. In my case it is not possible to
analyze the best equation found theoretically, because it is just an equation which ts
best according to the tness function. I think in general one should not expect, to
get a short equation via the Genetic Programming approach which lends itself well to
economic interpretation. Maybe [Keb99] was only lucky, or he restricted the problem
domain so that no other type of equation was able to emerge.</p>
      <p>Still this thesis has shown that Genetic Programming is also suitable for a complex
type of model (GARCH) and with a broad range of input parameters. [Keb99] has
shown that this approach is also suitable for American options.</p>
      <sec id="sec-8-1">
        <title>Chapter 8</title>
      </sec>
      <sec id="sec-8-2">
        <title>Conclusion</title>
        <p>This master thesis uses for the rst time the Genetic Programming approach to price
options which follow a GARCH process. The data sample is produced via the well
known Monte Carlo simulation method. The range of the simulated data is much
higher than in other existing approaches. This leads to the situation that all European
call options with an expiration time of up to 90 trading days are covered. The only
additional assumption is that the underlying follows a GARCH(1,1) process, where one
can nd a lot of empirical evidence that this assumption is realistic.</p>
        <p>Also new is the usage of di erent settings for the Genetic Programming approach
in the area of option pricing. A con guration with and without mutation is tested with
di erent bloat control methods. Additionally three di erent distribution functions are
used. As a state-of-the-art feature, the new approach of Automatic De ned Functions
is utilized. A hybrid model with a Black-Scholes analog function is tried, too. It was
expected that this hybrid model would harmonize well with the Automatic De ned
Functions.</p>
        <sec id="sec-8-2-1">
          <title>Summary of the result</title>
          <p>The experiments lead to the conclusion that the easier settings are more successful
than the complicated ones. Mutation does not work well and the simplest bloat control
methods (depth limiting and parsimony pressure) are successful. At the same time the
use of a normal distribution function seems su cient, because the use of others does
not lead to better results. Even the use of Automatic De ned Functions and the hybrid
approach, respectively does not improve the results.</p>
          <p>The best equation found is about 25% better (in term of RMSE) suited to price
European call options following a GARCH process than the Black-Scholes formula.
Over- tting was avoided and the behavior of the equation is regular. It does not have
any speci c area where the quality of the equation is low. It o ers therefore reasonable
prices for all European call options which are traded at exchanges. The conclusion
is therefore that Genetic Programming is well suited to nd pricing equations in this
environment.
8.3</p>
        </sec>
        <sec id="sec-8-2-2">
          <title>Future issues</title>
          <p>The Genetic Programming approach has the property that with higher computer power,
the results tend to get better. Therefore, in a few years a repetition of my tests with a
more powerful computer might lead to better results. The eld of Genetic Programming
is still an active area of research. New results may show new con guration settings
which are especially bene cial in the environment of option pricing. Additionally,
there are still many more con gurations possible with the Automatic De ned Function
approach which I could not test in this master thesis due to limited time. Especially
the evolutionary nding of the best architecture seems to be promising, but resource
expensive at the same time.</p>
          <p>The eld of option pricing is also an area of intensive research. New models emerge,
like the NGARCH and the EGARCH to name just a few. These models also capture
the leverage e ect (compare with [DS01]). The more complicated the models will
become, the less likely it is that a closed formula can be derived. I conclude therefore
that in the future there will be increasing necessity for guided empirical model nding
methods like Genetic Programming.
List of Figures
3.1 Flowchart of a simple genetic algorithm. Source: [Koz92] . . . . . . . . 17
3.2 An example of a genetic program . . . . . . . . . . . . . . . . . . . . . 20
3.3 An example of a crossover operation . . . . . . . . . . . . . . . . . . . 22
6.1 UML diagram of the Genetic Programming kernel. Source: [Wei97] . . 37
6.2 UML diagram of Newran02B. Source: [Dav02] . . . . . . . . . . . . . . 39
6.3 UML diagram of GPOPdata . . . . . . . . . . . . . . . . . . . . . . . . 42
6.4 UML diagram of the whole program . . . . . . . . . . . . . . . . . . . . 45
2.1 Input data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
3.1 Control parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
4.1 Input data ranges in [Han98] . . . . . . . . . . . . . . . . . . . . . . . . 28
4.2 Parameter values in [DS01] . . . . . . . . . . . . . . . . . . . . . . . . . 29
4.3 Parameter range in [Keb99] . . . . . . . . . . . . . . . . . . . . . . . . 29
5.1 Input data and ranges . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
5.2 Terminal set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
5.3 Function set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
5.4 Di erent approaches used . . . . . . . . . . . . . . . . . . . . . . . . . 34
6.1 Properties of GPVariable. Source: [Wei97] . . . . . . . . . . . . . . . . 38
6.2 Some functions of the GNU Scienti c Library . . . . . . . . . . . . . . 40
6.3 Additional functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
6.4 Properties of GPVariable. Source: [Wei97] . . . . . . . . . . . . . . . . 42
6.5 Methods of MyGene . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
6.6 Methods of MyGP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
6.7 Methods of MyPopulation . . . . . . . . . . . . . . . . . . . . . . . . . 44
6.8 Executables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
7.1 Test cases for con guration identi cation . . . . . . . . . . . . . . . . . 47
7.2 Results of con guration identi cation . . . . . . . . . . . . . . . . . . . 48
7.3 Results of the t-statistic in percent . . . . . . . . . . . . . . . . . . . . 48
7.4 Fitness values of the ADF approach . . . . . . . . . . . . . . . . . . . . 50
7.5 Results of the best found equation . . . . . . . . . . . . . . . . . . . . . 52
7.6 Simulation of the process . . . . . . . . . . . . . . . . . . . . . . . . . . 52
7.7 Standard deviation and RMSE . . . . . . . . . . . . . . . . . . . . . . . 53
7.8 Average results of the process . . . . . . . . . . . . . . . . . . . . . . . 55</p>
          <p>Phelim Boyle, Mark Broadie, and Paul Glasserman. Monte carlo methods
for security pricing. Journal of Economic Dynamics and Control, pages
1267{1321, 1997.</p>
          <p>Tim Bollerslev, Ray Y. Chou, and Kenneth F. Kroner. ARCH modeling in
nance: a review of the theory and empirical evidence. Journal of
Econometrics, 52:5{95, 1992.</p>
          <p>Thomas Back, David B. Fogel, and Zbigniew Michalewicz. Handbook of
Evolutionary Computation. Oxford University Press, New York, 1997.
[BNKF98] Wolfgang Banzhaf, Peter Nordin, Robert E. Keller, and Frank D.
Francone. Genetic Programming - An Introduction. Morgan Kaufmann, San
Francisco, California, USA, 1998.
[BS73]
[DS95]
[DS01]</p>
          <p>Tim Bollerslev. Generalized autoregressive conditional heteroskedasticity.
Journal of Econometrics, 31:307{327, 1986.</p>
          <p>Fischer Black and Myron Scholes. The pricing of options and corporate
liabilities. Journal of Political Economy, 81:637{659, 1973.</p>
          <p>Robert B. Davis. Newran02b - a random number generator library.
Technical report, Statistics Research Associates Limited, Wellington, New
Zealand, 2002.</p>
          <p>Jin-Chuan Duan and Jean-Guy Simonato. Empirical Martingale Simulation
for Asset Prices. CIRANO Working Papers, 95s-43, 1995.</p>
          <p>Jin-Chuan Duan and Jean-Guy Simonato. American option pricing under
GARCH by a markov chain approximation. Journal of Economic Dynamics
&amp; Control, 25:1689{1718, 2001.</p>
          <p>Jin-Chuan Duan. The GARCH option pricing model. Mathematical
Finance, 5(1):13{32, 1995.</p>
          <p>Robert F. Engle. Autoregressive conditional heteroskedasticity with
estimates of the variance of u.k. in ation. Econometrica, 50:987{1008, 1982.
[KBAK99] John R. Koza, Forrest H. Bennett III, David Andre, and Martin A. Keane.</p>
          <p>Genetic Programming III, Darwinian Invention and Problem Solving.
Morgan Kaufmann Publishers, San Francisco, California, USA, 1999.</p>
          <p>Adam P. Fraser. Genetic Programming in C++. Technical Report 040,
University of Salford, Cybernetics Research Institute, 1994.</p>
          <p>M. Galassi et al. GNU Scienti c Library Reference Manual. Network
Theorie Ltd., Bristol, United Kingdom, 2 edition, 2004.</p>
          <p>Alois L. J. Geyer and Walter S. A. Schwaiger. GARCH E ekte in der
Optionsbewertung. Zeitschrift fur Betriebswirtschaft, 65(5):534{540, 1996.
Michael Hanke. Neural Network Approximation of Option Pricing Formulas
for Analytically Intractable Option Pricing Models. Journal of
Computational Intelligence in Finance, 5(5):20{27, Sep 1997.</p>
          <p>Michael Hanke. Optionsbewertung mit neuronalen Netzen. Dissertation,
Wirtschaftsuniversitat Wien, 1998.</p>
          <p>John H. Holland. Adaption in Natural and Arti cial Systems. University
of Michigan Press, 1975.</p>
          <p>John C. Hull. Options, futures, and other derivatives. Prentice Hall
International, Inc., Upper Saddle River, New Jersey, USA, fth edition, 2002.
John R. Koza et al. Genetic Programming IV: Routine Human-Competitive
Machine Intelligence. Kluwer Acadamic Publishers, 2003.</p>
          <p>Christian Keber. Option Pricing with the Genetic Programming Approach.
Journal of Computational Intelligence in Finance, 7(6):26{36, 1999.</p>
          <p>John R. Koza. Genetic Programming. The MIT Press, Cambridge,
Massachusetts, USA, 1992.</p>
          <p>John R. Koza. Genetic Programming II, Automatic Discovery of Reuseable
Programs. The MIT Press, Cambridge, Massachusetts, USA, 1994.</p>
          <p>Zbigniew Michalewicz. Genetic Algorithms + Data Structures = Evolution
Programs. Springer, Berlin, Germany, 1992.</p>
          <p>Salih N. Neftci. An Introduction to the Mathematics of Financial
Derivatives. Acadamic Press, San Diego, California, USA, second edition, 2000.
John P. Nolan. Numerical calculation of stable densities and distribution
functions. Commun. Statist. - Stochastic Models, 13(4):759{774, 1997.</p>
          <p>Liviu Panait and Sean Luke. Alternative Bloat Control Methods. In Lecture
Nodes in Computer Science 3103, pages 630{641. Springer-Verlag, 2004.
Craig W. Reynolds. An evolved, vision-based behavioral model of
coordinated group motion. In Meyer and Wilson, editors, From Animals to
Animats (Proceedings of Simulation of Adaptive Behaviour). MIT Press,
1992.</p>
          <p>Andy Singleton. Genetic Programming with C++. BYTE Magazin,
February 1994.</p>
          <p>Bjarne Stroustrup. The C++ Programming Language. Addison Wesley
Longman, Reading Mass, USA, third edition, 1998.</p>
          <p>Reinhard K. Viertl. Einfuhrung in die Stochastick. Springer-Verlag, Wien,
second edition, 1997.</p>
          <p>Thomas Weinbrenner. The Genetic Programming Kernel. Technical report,
Institute for Mechatronics, Technical University of Darmstadt, 1997.</p>
          <p>V. M. Zolotarev. One-dimensional Stable Distributions. Amer. Math. Soc.
Transl. of Math. Monographs, 65, 1986.</p>
        </sec>
      </sec>
    </sec>
  </body>
  <back>
    <ref-list>
      <ref id="ref1">
        <mixed-citation>
          8.1 New
          <string-name>
            <surname>approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</surname>
          </string-name>
          <article-title>58 8.2 Summary of the result</article-title>
          <string-name>
            <surname>. . . . . . . . . . . . . . . . . . . . . . . . . . . 58</surname>
          </string-name>
          <year>8</year>
          .3 Future
          <string-name>
            <given-names>issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 Object</given-names>
            <surname>Management</surname>
          </string-name>
          <string-name>
            <surname>Group</surname>
          </string-name>
          , Inc. OMG Uni ed Modeling Language Specication,
          <source>Ver. 1</source>
          .5,
          <string-name>
            <surname>March</surname>
          </string-name>
          <year>2003</year>
          .
        </mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>